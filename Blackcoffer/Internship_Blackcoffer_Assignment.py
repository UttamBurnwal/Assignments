# -*- coding: utf-8 -*-
"""Internship_Blackcoffer_Assignment

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VjGgAmDq-SMzxYGyOg99KkferQjhuOjd

## Web Scrapping (Data Extraction)

For each of the articles, given in the input.xlsx file, extract the article text and save the extracted article in a text file with URL_ID as its file name.
"""

import pandas as pd
import requests
from bs4 import BeautifulSoup

input_data = pd.read_excel('Input.xlsx')
input_data.head(5)

input_data.tail(5)

url = input_data['URL'][0]
url

headers = {
    'User-Agent': 'My User Agent 1.0',
    'From': 'burnwalbittu@gmail.com'  # This is another valid field
}
page = requests.get(url, headers=headers)

soup = BeautifulSoup(page.text, "html.parser")

print(soup.prettify())

title = soup.find(name="h1", attrs={"class":"entry-title"})
print(title.get_text())

content = soup.find(name="div", attrs={"class":"td-post-content"})
print(content.get_text())

"""**Automating the entire process and from each of the articles given in the input.xlsx file, extracting only the article title and the article text. Later on saving the extracted article in a text file with URL_ID as its file name.**
 

"""

headers = {
    'User-Agent': 'My User Agent 1.0',
    'From': 'burnwalbittu@gmail.com' 
}
for i in range(len(input_data)):
  file = open(f"{input_data['URL_ID'][i]}.txt", "w")
  url = input_data['URL'][i]
  page = requests.get(url, headers = headers)
  soup = BeautifulSoup(page.text, "html.parser")
  title = soup.find(name="h1", attrs={"class":"entry-title"})
  title_c = title.get_text()
  content = soup.find(name="div", attrs={"class":"td-post-content"})
  content_c = content.get_text()
  file.write(title_c)
  file.write(content_c)
  file.flush()
  file.close

"""## Data Analysis

**For each of the extracted texts from the article, perform textual analysis and compute variables**

1.	POSITIVE SCORE
2.	NEGATIVE SCORE
3.	POLARITY SCORE
4.	SUBJECTIVITY SCORE
5.	AVG SENTENCE LENGTH
6.	PERCENTAGE OF COMPLEX WORDS
7.	FOG INDEX
8.	AVG NUMBER OF WORDS PER SENTENCE
9.	COMPLEX WORD COUNT
10.	WORD COUNT
11.	SYLLABLE PER WORD
12.	PERSONAL PRONOUNS
13.	AVG WORD LENGTH




"""

# Importing Required Packages

import re
import nltk
nltk.download('punkt')
nltk.download('wordnet')
from nltk.tokenize import word_tokenize, sent_tokenize
from nltk.stem import WordNetLemmatizer
lemma = WordNetLemmatizer()

with open("StopWords_Generic.txt", "r") as sw:
  stop_words = sw.read().lower()
  stopwords_list = stop_words.split('\n')

with open("PositiveWords.txt", "r") as pos:
  pos_words = pos.read().lower()
  pos_list = pos_words.split('\n')

with open("NegativeWords.txt", "r") as neg:
  neg_words = neg.read().lower()
  neg_list = neg_words.split('\n')

"""**Data Analysis**"""

with open("1.txt", "r") as text:
  text = text.read().lower()
  text = text.split('\n')
text = str(text)
text

# Removing all character except string

corp = re.sub(r'[^a-zA-Z]',' ', text).strip()
corp

# Performing tokenization and converting words into tokens

tokens = word_tokenize(corp)
tokens

# Removing stopwords from the list of tokens

words = [t for t in tokens if t not in stopwords_list]
words

# Performing Lemmatization on each word

lemmatize_text = [lemma.lemmatize(w) for w in words]
lemmatize_text

"""**Computing Variables**"""

# Positive Score: This score is calculated by assigning the value of +1 for each word if found in the Positive Dictionary and then adding up all the values.
def positivescore(text):
  score = 0
  for word in text:
    if word in pos_list:
      score = score + 1
  return score

# Negative Score: This score is calculated by assigning the value of -1 for each word if found in the Negative Dictionary and then adding up all the values. 
# We multiply the score with -1 so that the score is a positive number.

def negativescore(text):
  score = 0
  for word in text:
    if word in neg_list:
      score = score - 1
      score = score*(-1)
  return score

# Polarity Score: This is the score that determines if a given text is positive or negative in nature. It is calculated by using the formula: 
# Polarity Score = (Positive Score â€“ Negative Score)/ ((Positive Score + Negative Score) + 0.000001)

def polarityscore(positive_score, negative_score):
  ps = (positive_score - negative_score)/((positive_score + negative_score) + 0.000001)
  return round(ps, 4)

# Subjectivity Score: This is the score that determines if a given text is objective or subjective. It is calculated by using the formula: 
# Subjectivity Score = (Positive Score + Negative Score)/ ((Total Words after cleaning) + 0.000001)

def subjectivescore(positive_score, negative_score, text):
  ss = (positive_score - negative_score)/(len(text) + 0.000001)
  return round(ss, 4)

# Analysis of Readability is calculated using the Gunning Fox index formula described below.
# Average Sentence Length = the number of words / the number of sentences

def avg_sen_len(words, sentences):
  asl = len(words)/len(sentences)
  return round(asl)

# Calculating Vowels, Complex Word and Percentage of Complex words

def percent_complex_word(tokens):
  complexword = 0
  vowels=0
  for word in tokens:
      
      if word.endswith(('es','ed')):
          pass
      else:
          for w in word:
              if(w=='a' or w=='e' or w=='i' or w=='o' or w=='u'):
                  vowels += 1
          if(vowels > 2):
              complexword += 1

  complex_word_percentage = complexword/len(tokens)
  
  return vowels, complexword, round(complex_word_percentage,2)

# Fog Index = 0.4 * (Average Sentence Length + Percentage of Complex words)

def fog_index(avg_sent_length, percentage_complex_word):
  fi = 0.4*(avg_sent_length+percentage_complex_word)
  return round(fi,3)

# Calculate Personal Pronouns

def calculate_personal_pronoun(text):
  pp = 0
  for word in text:
    if(word=='i' or word=='we' or word=='my' or word=='ours' or word=='us'):
      pp += 1

  return pp

# Average Word Length

def avg_word_len(text):
  count = 0
  for word in text:
    for w in word:
      count += 1
  avg  = count/len(text)
  return round(avg)

# Automating the entire process and computing variables for each article and storing into empty lists

Positive_Score = []
Negative_Score = []
Polarity_Score = []
Subjective_Score = []
Average_Sentence_Length = []
Percentage_of_Complex_words = []
Fog_Index = []
Average_Number_of_Words_Per_Sentence = [] 
Complex_Words = []
Word_Count = []
Syllable_Count_Per_Word = []
Personal_Pronouns = []
Average_Word_Length = []


for i in range(len(input_data)):
  with open(f"{i+1}.txt", "r") as text:
    text = text.read().lower()
    text = text.split('\n')

  text = str(text)
  corp = re.sub(r'[^a-zA-Z]',' ', text).strip()
  tokens = word_tokenize(corp)
  sent_token = sent_tokenize(text)
  words = [t for t in tokens if t not in stopwords_list]
  lemmatize_text = [lemma.lemmatize(w) for w in words]

  # Extracting Derived variables

  positive_score = positivescore(lemmatize_text)
  Positive_Score.append(positive_score)

  negative_score = negativescore(lemmatize_text)
  Negative_Score.append(negative_score)

  Polarity_Score.append(polarityscore(positive_score,negative_score))

  Subjective_Score.append(subjectivescore(positive_score, negative_score, lemmatize_text))

  # Analysis of Readability

  avg_sent_length = avg_sen_len(lemmatize_text, sent_token)
  Average_Sentence_Length.append(avg_sent_length)

  vowels, complex_word_count, percentage_complex_word = percent_complex_word(lemmatize_text)
  Percentage_of_Complex_words.append(percentage_complex_word)
  Syllable_Count_Per_Word.append(vowels)
  Complex_Words.append(complex_word_count)
  

  Fog_Index.append(fog_index(avg_sent_length,percentage_complex_word))
  Average_Number_of_Words_Per_Sentence.append(avg_sent_length)

  Word_Count.append(len(lemmatize_text))
  Personal_Pronouns.append(calculate_personal_pronoun(lemmatize_text))
  Average_Word_Length.append(avg_word_len(lemmatize_text))

# Reading the output file

output_data = pd.read_excel('Output_Data_Structure.xlsx')

output_data.head()

output_data.columns

output_data['POSITIVE SCORE'] = Positive_Score
output_data['NEGATIVE SCORE'] = Negative_Score
output_data['POLARITY SCORE'] = Polarity_Score
output_data['SUBJECTIVITY SCORE'] = Subjective_Score
output_data['AVG SENTENCE LENGTH'] = Average_Sentence_Length
output_data['PERCENTAGE OF COMPLEX WORDS'] = Percentage_of_Complex_words
output_data['FOG INDEX'] = Fog_Index
output_data['AVG NUMBER OF WORDS PER SENTENCE'] = Average_Number_of_Words_Per_Sentence
output_data['COMPLEX WORD COUNT'] = Complex_Words
output_data['WORD COUNT'] = Word_Count
output_data['SYLLABLE PER WORD'] = Syllable_Count_Per_Word
output_data['PERSONAL PRONOUNS'] = Personal_Pronouns
output_data['AVG WORD LENGTH'] = Average_Word_Length

output_data

# Exporting File

output_data.to_excel('Output_Data_Structure_File.xlsx', index = False, header = True)